# Azure Data Factory Project â€“ COVID-19 Data Engineering Pipeline

ğŸš€ This project showcases a complete end-to-end Azure Data Factory (ADF) pipeline for ingesting, transforming, and loading COVID-19 datasets. The pipeline includes data validation, transformation, storage integration, Databricks, and Power BI integration.

---

## ğŸ› ï¸ Tech Stack

- **Azure Data Factory (ADF)**
- **Azure Data Lake Gen2**
- **Azure SQL Database**
- **Azure Databricks**
- **Power BI**
- **Azure DevOps (for CI/CD)**

---

## ğŸ§ª Scenarios Implemented

1. âœ… **Triggering pipelines** when a new file becomes available.
2. ğŸ” **Validating file contents** before processing.
3. ğŸ§¹ **Deleting source files** post-processing.
4. â± **Schedule and tumbling window triggers**
5. ğŸ“¥ **Ingesting external data** (e.g., from HTTP)
6. ğŸ”„ **Transformations**
   - Filter
   - Pivot
   - Lookup (left outer join)
7. ğŸ§© **Databricks integration**
   - Mounting Azure Data Lake
   - Running notebooks via job clusters
8. ğŸ **Production-ready pipelines**
9. ğŸ“Š **Power BI dashboards**

---

## ğŸ” CI/CD Process

- Used Azure DevOps for feature branching and pull requests.
- Implemented Dev â†’ QA â†’ Prod pipeline promotions.
- Used parameterized pipelines for environment-specific values.

---

## ğŸ“¸ Screenshots

Screenshots are included in the repo to illustrate:
- Pipeline configurations
- Trigger setup
- Data Lake and Databricks mounting
- Parameter passing
- Power BI integration

---

